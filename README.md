In our project "Testing linear-attention Transformers," we delve into the performance of linear-attention Transformers. 
Our study focuses on comparing Performers architectures with regular Transformers models and Linformers architectures on small image classification tasks. 
We explore the innovative use of linear attention mechanisms to scale to longer input sequence lengths without quadratic complexity explosions, 
particularly beneficial for processing videos with extended sequential context. By combining convolutional neural network (CNN) features with fast 
vision Transformer encoders, we aim to enhance model accuracy and efficiency. Our initial experiments show promising results, indicating potential 
synergies between CNNs for local feature extraction and Transformers for global modeling capacity. This project underscores the importance of leveraging 
simplified Transformer variants for improved scalability and performance in sequence modeling tasks, paving the way for new hybrid techniques in machine learning. 
Overall, our research contributes to the ongoing exploration of advanced neural network architectures and their applications in data mining and machine learning tasks.

